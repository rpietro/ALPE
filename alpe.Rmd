# Agile Learning Problem Elicitation (ALPE) framework: Educational technology and N-of-1 reproducible trial among physicians


Guilherme Isaac Schreiber Litwinski  
Guilherme Cunha  
Jo√£o Ricardo Vissoci  
Bruno Melo  
Ricardo Pietrobon



<!--

communicate through wechat??? http://dev.wechat.com/wechatapi
incentive through the use of information from previous questions, even if repeated??
json
key taxonomy
copyright issues vs present info from page
databases for most common topics
present links
infographics
useful even if not complete answer?

https://telegram.org/
 -->

<!-- http://transag.sourceforge.net/ -->

## Abstract



## Introduction

Despite its best intentions, Healthcare Learning Technologies have been plagued by solutions that address either (1) what educators think it is important for healthcare professionals to learn or (2) what technologists are able to deliver. In contrast with these top approaches, technologies should be delivered with a focus on solving real problems from healthcare professionals. To our knowledge, however, no previous comprehensive framework has been described to date that might elicit information needs during a regular daily clinical practice.

* Learning problem elicitation methods among healthcare professionals
* Agile and its focus on stakeholders through iterative cycles

The objective of this study is therefore to describe an implementation of the Agile Learning Problem Elicitation (ALPE) framework, specifically describing its process, technology, analysis and reporting among neurologists. A further description is provided on how this framework could be coupled with N-of-1 trials to validate learning technologies that might address the problems emerging from ALPE.


## Methods


|Trial design|Planned number and duration of each period, run-in and wash out with rationale, series of N- of-1 trials|


|Ethics|IRB approval, including details on informed consent or why it was waived|


### Participants



* Two physicians, neurologist and general clinician, seeing patients in their daily practice. rounds, emergency room
* recruited through direct contact
* recording voice recorded notes about learning needs, e.g., "would like to know what differential diagnosis is", "what are alternative drugs for condition X"
* recordings did not contain any information about specific patients
* participants encouraged to take voice recording note at the very moment when needs arose



### Intervention


#### Daily diary arm

* traditional method
* write down questions at the end of the day
* send them by email


#### Inbound arm


* [NetMemo Plus Voice Recorder](https://play.google.com/store/apps/details?id=com.netify.netmemopro&hl=en)
    * recorded at the time the need arose
* Brief outline at night
    * listen to notes taken during the day
    * forward to analyst (RP) along with any additional notes regarding insights, additional comments, or anything that could bring additional depth to the voice recorded note
* transcript analysis using [RQDA](http://rqda.r-forge.r-project.org/) 
<!-- https://www.youtube.com/playlist?list=PL66CB2FF65368715C&feature=plcp -->
* nightly reporting with Rmd file 

<!-- * feedback reporting tool
    * [Django](https://www.djangoproject.com/) framework
    * [Cerely](http://www.celeryproject.org/) task queueing
* weekly meeting with subject until reaches emergence saturation
 -->


### 

#### Outcomes

<!-- |Primary and secondary, including factors such as information absorption, ability to solve problems, User eXperience (UX) and ability to put information to real-world practice| -->

### Sample size

* Reproducible through scripts and links to preliminary data or relevant publications


### Stopping rules
Set upfront or decided during the trial


### Randomization

* Sequence generation
* allocation concealment
* blinding


### Data analysis
* Fully reproducible with corresponding scripts, assumption checking (carry-over effect, period effects, intra-subject correlation), efficacy evaluation, synthesis methods if more than one N-of-1 is being used (how heterogeneity between participants was assessed, [PRISMA guidelines](http://www.prisma-statement.org/))



### Semantic Reproducible Research protocol

<!-- grab from previous sections -->
<!-- |Reproducicle research|Scripts available on sites such as [Github](https://github.com/), data available on sites such as Github and [Figshare](http://figshare.com/), storage of software packages] -->

* data
* scripts
* [Rmd](https://github.com/rstudio/rmarkdown)
* software
* N-of-1 data compilation - [Use-case driven](http://www.researchgate.net/publication/221465095_A_Proposal_for_a_Unified_Process_for_Ontology_Building_UPON/file/79e4150a24778016df.pdf) [ontology](http://www.w3.org/RDF/) modeling which extends [Cook and Pietrobon, 2007](http://www.ncbi.nlm.nih.gov/pubmed/17847604), connection with R packages|



## Results

RQDA tables and graphics

## Discussion

* integration with N-of-1 trials
    * [AHRQ, 2014](http://effectivehealthcare.ahrq.gov/ehc/products/534/1844/n-1-trials-report-130213.pdf) 
    * [Personalized Lifelong Learning Consortium, 2014]() arXiv paper
    * Open edX and randomization framework Jacinto
